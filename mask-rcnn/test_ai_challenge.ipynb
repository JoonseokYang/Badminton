{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gpu_number = '0'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu_number\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import PIL \n",
    "\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# root: 현재 폴더\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "sys.path.append(ROOT_DIR) \n",
    "\n",
    "# model 들어있는 폴더\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"models\", \"shoes_300(200).h5\") # mylogs에 최종 모델 넣어놔야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 조정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import badminton\n",
    "config = badminton.CocoConfig() # 기본 설정들. hyperparameter\n",
    "\n",
    "DATA_DIR = \"/home/joon/dataset\"  # TODO: enter value here\n",
    "model_name = \"shoes_300(200).h5\" #\"emo_frame_E01-E24_201020.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Images: 20\n",
      "Classes: ['BG', 'shoes']\n"
     ]
    }
   ],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "#config.display()\n",
    "\n",
    "DEVICE = \"/gpu:{}\".format(gpu_number)  # /cpu:0 or /gpu:0\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "dataset = badminton.CocoDataset()\n",
    "dataset.load_coco(DATA_DIR, \"test\") # test로 바꾸기\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference 모드로 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /home/joon/Documents/mask-rcnn/models/shoes_300(200).h5\n"
     ]
    }
   ],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)\n",
    "\n",
    "# Load weights\n",
    "model_path = os.path.join(MODEL_DIR)\n",
    "\n",
    "print(\"Loading weights \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nvisualize.draw_boxes(original_image, boxes=r[\\'rois\\'], refined_boxes=None,\\n                     masks=None, captions=None, visibilities=None,\\n                     title=\"FACE\", ax=ax)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "import cv2\n",
    "\n",
    "def random_colors(N):\n",
    "    np.random.seed(1)\n",
    "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"apply mask to image\"\"\"\n",
    "    for n, c in enumerate(color):\n",
    "        image[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
    "            image[:, :, n]\n",
    "        )\n",
    "    return image\n",
    "\n",
    "\n",
    "def display_instances(image, boxes, masks, ids, names, scores):\n",
    "    \"\"\"\n",
    "        take the image and results and apply the mask, box, and Label\n",
    "    \"\"\"\n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "\n",
    "    if not n_instances:\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "        \n",
    "        if names[ids[i]] == \"shoes\": ###\n",
    "            color = (124,78,30)\n",
    "        #elif names[ids[i]] == \"crate\":\n",
    "        #   color = (0,255,0)\n",
    "            \n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        label = names[ids[i]]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "        mask = masks[:, :, i]\n",
    "\n",
    "        image = apply_mask(image, mask, color)\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        image = cv2.putText(\n",
    "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "        )\n",
    "    return image\n",
    "\n",
    "\n",
    "test_data_path = \"/home/joon/dataset/test/\" # 아무 사진이나 테스트 하는 부분\n",
    "Save_DIR = \"/home/joon/Documents/mask-rcnn/result\"\n",
    "\n",
    "for i, image_name in enumerate([f for f in sorted(os.listdir(test_data_path)) if 'jpg' in f]):\n",
    "    image_path = os.path.join(test_data_path, image_name)\n",
    "    original_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "    #original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, config, 101, use_mini_mask=False)\n",
    "    # If grayscale. Convert to RGB for consistency.\n",
    "    if original_image.ndim != 3:\n",
    "        original_image = skimage.color.gray2rgb(original_image)\n",
    "\n",
    "    # Run object detection\n",
    "\n",
    "\n",
    "    results = model.detect([original_image], verbose=0)\n",
    "\n",
    "    # Display results\n",
    " \n",
    "    r = results[0]\n",
    "    #print(r)\n",
    "\n",
    "\n",
    "    save = display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset.class_names, r['scores'])\n",
    "    \n",
    "    name = 'detected_'+image_name\n",
    "    name = os.path.join(Save_DIR, name)\n",
    "    cv2.imwrite(name,save)\n",
    "\n",
    "'''\n",
    "visualize.draw_boxes(original_image, boxes=r['rois'], refined_boxes=None,\n",
    "                     masks=None, captions=None, visibilities=None,\n",
    "                     title=\"FACE\", ax=ax)\n",
    "'''\n",
    "#print (r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : shoes_300(t).h5\n",
      "1\n",
      "0, elapsed : 0.00615m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "10, elapsed : 0.0392m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "mAPs = []\n",
    "started = time.time()\n",
    "print ('model : {}'.format(model_name))\n",
    "for image_id in range(len(dataset.image_ids)):\n",
    "    \n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "    \n",
    "    results = model.detect([original_image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    test_result = utils.compute_ap(gt_boxes=gt_bbox, gt_class_ids=gt_class_id, gt_masks=gt_mask, \n",
    "                                   pred_boxes=r['rois'], pred_class_ids=r['class_ids'], \n",
    "                                   pred_scores=r['scores'], pred_masks=r['masks'], \n",
    "                                   iou_threshold=0.5)\n",
    "    \n",
    "    mAP, precision, recall, overlap = test_result[0], test_result[1], test_result[2], test_result[3]\n",
    "    mAPs.append(mAP)\n",
    "    \n",
    "    if image_id % 10 == 0:\n",
    "        print ('{}, elapsed : {:.3}m'.format(image_id, (time.time()-started)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badminton_300_mAP = sum(mAPs)/len(mAPs)\n",
    "badminton_300_mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection and make gt & dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수정해야할 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'badminton_100.h5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/joon/dataset'\n",
    "gt_save_path = os.path.join(root_dir, 'ground_truth')\n",
    "dr_save_path = os.path.join(root_dir, 'detection_results', '{}'.format(model_name[:-3]))\n",
    "if not os.path.isdir(gt_save_path):\n",
    "    os.mkdir(gt_save_path)\n",
    "if not os.path.isdir(dr_save_path):\n",
    "    os.makedirs(dr_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = '/home/joon/dataset'\n",
    "data_dir = os.path.basename(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json files & class ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'player', 2: 'racket'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_data_path = os.path.join(DATA_DIR, 'test')\n",
    "annotations_path = os.path.join(DATA_DIR, 'annotations')\n",
    "test_anno_path = os.path.join(annotations_path, 'instances_test.json')\n",
    "train_anno_path = os.path.join(annotations_path, 'instances_train.json')\n",
    "val_anno_path = os.path.join(annotations_path, 'instances_val.json')\n",
    "\n",
    "loaded = json.load(open(test_anno_path))\n",
    "class_ids_info = {i['id']:i['name'] for i in loaded['categories'] }\n",
    "print (class_ids_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-truth (Mask RCNN -> YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = {}\n",
    "for label_info in loaded['annotations']:\n",
    "    cate_id = label_info['category_id']\n",
    "    class_ = class_ids_info[cate_id]\n",
    "    img_id = label_info['image_id']\n",
    "    img_name = loaded['images'][img_id-1]['file_name']\n",
    "    bbox = label_info['bbox']\n",
    "    class_n_bbox = [class_, str(int(bbox[0])), str(int(bbox[1])), str(int(bbox[0])+int(bbox[2])), str(int(bbox[1])+int(bbox[3]))]\n",
    "    if img_name not in matched:\n",
    "        matched[img_name] = [class_n_bbox]\n",
    "    else:\n",
    "        matched[img_name].append(class_n_bbox)\n",
    "\n",
    "for img, gt_bboxes_info in matched.items():\n",
    "    gt_file_name = img.replace('jpg', 'txt')\n",
    "    gt_file_path = os.path.join(gt_save_path, gt_file_name)\n",
    "    writing = '\\r\\n'.join([' '.join(gbi) for gbi in gt_bboxes_info ])\n",
    "    with open(gt_file_path, 'w') as f:\n",
    "        f.write(writing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection results (Mask RCNN -> YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0, elapsed : 0.174m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "10, elapsed : 2.05m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "20, elapsed : 3.81m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "30, elapsed : 5.71m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "40, elapsed : 7.59m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "50, elapsed : 9.37m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "started = time.time()\n",
    "for i, image_name in enumerate([f for f in sorted(os.listdir(test_data_path)) if 'jpg' in f]):\n",
    "    \n",
    "    image_path = os.path.join(test_data_path, image_name)\n",
    "    original_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Run object detection\n",
    "    results = model.detect([original_image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    writing = []\n",
    "    for roi, c_id, score in zip(r['rois'], r['class_ids'], r['scores']):\n",
    "        writing.append(' '.join([class_ids_info[c_id], \n",
    "                                 str(score), str(int(roi[1])), str(int(roi[0])), str(int(roi[3])), str(int(roi[2]))]))\n",
    "    \n",
    "    write_input = '\\r\\n'.join(writing)\n",
    "    save_path = os.path.join(dr_save_path, image_name.replace('jpg', 'txt'))\n",
    "    \n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(write_input)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print ('{}, elapsed : {:.3}m'.format(i, (time.time()-started)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect and save bbox to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joon/dataset/test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nepisode_dir = 'mfE01_fps{}'.format(fps)\\nepisode_path = os.path.join(episode_root_path, episode_dir)\\n\\nif not os.path.isdir(episode_path): os.mkdir(episode_path)\\ndetected_path = os.path.join(emo_image_path, 'Detection_Cropping', '{}_detected_{}_{}_fps{}'.format(episode_dir[2:5], model_name[18:-3], score_threshold, fps))\\nif not os.path.isdir(detected_path): os.mkdir(detected_path)\\n\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL \n",
    "import cv2\n",
    "import time\n",
    "\n",
    "score_threshold = 0.7\n",
    "fps = 10\n",
    "\n",
    "emo_image_path = '/home/joon/dataset/test'\n",
    "#episode_root_path = os.path.join(emo_image_path, 'mfE01_E24_fps{}'.format(fps))\n",
    "print(emo_image_path)\n",
    "'''\n",
    "episode_dir = 'mfE01_fps{}'.format(fps)\n",
    "episode_path = os.path.join(episode_root_path, episode_dir)\n",
    "\n",
    "if not os.path.isdir(episode_path): os.mkdir(episode_path)\n",
    "detected_path = os.path.join(emo_image_path, 'Detection_Cropping', '{}_detected_{}_{}_fps{}'.format(episode_dir[2:5], model_name[18:-3], score_threshold, fps))\n",
    "if not os.path.isdir(detected_path): os.mkdir(detected_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "000, elapsed : 20.8m\n"
     ]
    }
   ],
   "source": [
    "id_class_matched = {1: 'player', 2: 'racket' }\n",
    "\n",
    "def cropsizer(image, bboxs):\n",
    "    image = PIL.Image.open(image) \n",
    "\n",
    "    for bound in bboxs:\n",
    "        np_image = np.asarray( image.crop(bound) ) \n",
    "\n",
    "    return np_image, bboxs\n",
    "\n",
    "'''\n",
    "######################################################\n",
    "started = time.time()\n",
    "for episode_dir in sorted(os.listdir(emo_image_path)):\n",
    "    \n",
    "    episode_path = os.path.join(emo_image_path, episode_dir)\n",
    "    if not os.path.isdir(episode_path): \n",
    "        os.mkdir(episode_path)\n",
    "        \n",
    "    detected_path = os.path.join(emo_image_path, 'Detection_Cropping', \n",
    "                                 '{}_detected_{}_{}_fps{}'.format(episode_dir[2:5], model_name[18:-3], score_threshold, fps))\n",
    "    \n",
    "    if not os.path.isdir(detected_path): \n",
    "        os.mkdir(detected_path)\n",
    "######################################################\n",
    "'''\n",
    "        \n",
    "    #started = time.time()\n",
    "for i, img_file in enumerate([f for f in sorted(os.listdir(emo_image_path)) if 'jpg' in f]):\n",
    "\n",
    "    image_path = os.path.join(emo_image_path, img_file)\n",
    "    original_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    results = model.detect([original_image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    detected_path = os.path.join(emo_image_path, 'Detection_Cropping', )\n",
    "    \n",
    "    if not os.path.isdir(detected_path): \n",
    "        os.mkdir(detected_path)\n",
    "\n",
    "    if len(r['rois']) >= 1:\n",
    "        for roi, c_id, score in zip(r['rois'], r['class_ids'], r['scores']):\n",
    "            if score >= score_threshold:\n",
    "                bbox_ = np.array([[roi[1], roi[0],roi[3],roi[2]]])\n",
    "                result, _ = cropsizer(image_path, bbox_)\n",
    "                result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "                detected = id_class_matched[c_id]\n",
    "                detected_save_path = os.path.join(detected_path, '{}_{}.jpg'.format(img_file[:-4], detected))\n",
    "                cv2.imwrite(detected_save_path, result)\n",
    "\n",
    "        #if i%100 == 0:\n",
    "            #print ('{}, elapsed : {:.3}m'.format(i, (time.time()-started)/60))\n",
    "print ('{}, elapsed : {:.3}m'.format(episode_dir[2:5], (time.time()-started)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO v2 test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from lxml import etree\n",
    "import xml.etree.cElementTree as ET\n",
    "from xml.etree.cElementTree import parse\n",
    "import json\n",
    "import time\n",
    "\n",
    "root_dir = '/home/joon/dataset'\n",
    "yolo_dr_path = os.path.join(root_dir, 'detection_results','badminton_100')\n",
    "yolo_gt_path = os.path.join(root_dir, 'ground_truth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player': 1, 'racket': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = json.load(open('/home/joon/dataset/test_option.json'))\n",
    "categories = loaded['CATEGORIES']\n",
    "categories_list = {i['name']:i['id'] for i in categories}\n",
    "categories_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0, elapsed : 0.216m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "10, elapsed : 1.99m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "20, elapsed : 3.85m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "30, elapsed : 5.7m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "40, elapsed : 7.54m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "50, elapsed : 9.32m\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "mAPs, precisions, recalls, overlaps = [],[],[],[]\n",
    "started = time.time()\n",
    "\n",
    "for image_id, (dr_txt, gt_txt) in enumerate(zip(sorted(os.listdir(yolo_dr_path)), [f for f in sorted(os.listdir(yolo_gt_path)) if 'txt' in f])):\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "    results = model.detect([original_image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    dr_txt_path = os.path.join(yolo_dr_path, dr_txt)\n",
    "    gt_txt_path = os.path.join(yolo_gt_path, gt_txt)\n",
    "    \n",
    "    with open(dr_txt_path, 'r') as f:\n",
    "        detected_list = f.readlines()\n",
    "        if len(detected_list) == 0:\n",
    "            r['rois'] = np.empty((0,4)).astype(np.int32)\n",
    "            r['class_ids'] = np.empty((0)).astype(np.int32)\n",
    "            r['masks'] = np.empty((720,1280,0)).astype(np.float64)\n",
    "            r['scores'] = np.empty((0)).astype(np.float32)\n",
    "        else:\n",
    "            detected_list = [dl.replace('\\n', '') for dl in detected_list]\n",
    "            r['rois'] = np.array([[int(i.split(' ')[3]), int(i.split(' ')[2]), \n",
    "                                   int(i.split(' ')[5]), int(i.split(' ')[4])] for i in detected_list])\n",
    "            r['class_ids'] = np.array([categories_list[i.split(' ')[0]] for i in detected_list])\n",
    "        \n",
    "    with open(gt_txt_path, 'r') as f:\n",
    "        gt_list = f.readlines()\n",
    "        gt_list = [gt.replace('\\n', '') for gt in gt_list]\n",
    "        gt_bbox =  np.array([[int(i.split(' ')[2]), int(i.split(' ')[1]), \n",
    "                              int(i.split(' ')[4]), int(i.split(' ')[3])] for i in gt_list])\n",
    "        gt_class_id = np.array([categories_list[i.split(' ')[0]] for i in gt_list])\n",
    "        \n",
    "#    print (r['rois'], ' vs ', gt_bbox)\n",
    "#    print (r['class_ids'], ' vs ', gt_class_id)\n",
    "#    print ('-'*100)\n",
    "\n",
    "    test_result = utils.compute_ap(gt_boxes=gt_bbox, gt_class_ids=gt_class_id, gt_masks=gt_mask, \n",
    "                                   pred_boxes=r['rois'], pred_class_ids=r['class_ids'], pred_scores=r['scores'], \n",
    "                                   pred_masks=r['masks'], iou_threshold=0.5)\n",
    "    mAP, precision, recall, overlap = test_result[0], test_result[1], test_result[2], test_result[3]\n",
    "    mAPs.append(mAP)\n",
    "    \n",
    "    if image_id % 10 == 0:\n",
    "        print ('{}, elapsed : {:.3}m'.format(image_id, (time.time()-started)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolov2_mAP = sum(mAPs)/len(mAPs)\n",
    "yolov2_mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Badminton",
   "language": "python",
   "name": "mask-rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
